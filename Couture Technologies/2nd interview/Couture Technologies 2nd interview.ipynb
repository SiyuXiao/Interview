{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129927"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Please put the code in the same directory with 'SimplifiedFashionDataset'\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import torch.optim as optim\n",
    "Jumpsuit = 'SimplifiedFashionDataset/Jumpsuit'\n",
    "Jumpsuit_label = np.full(len(os.listdir(Jumpsuit)), 0)\n",
    "Dress = 'SimplifiedFashionDataset/Dress'\n",
    "Dress_label = np.full(len(os.listdir(Dress)), 1)\n",
    "Skirt = 'SimplifiedFashionDataset/Skirt'\n",
    "Skirt_label = np.full(len(os.listdir(Skirt)), 2)\n",
    "Tee = 'SimplifiedFashionDataset/Tee'\n",
    "Tee_label = np.full(len(os.listdir(Tee)), 3)\n",
    "label_name = {0:'Jumpsuit', 1:'Dress', 2:'Skirt', 3:'Tee'}\n",
    "file_name = os.listdir(Jumpsuit) + os.listdir(Dress) + os.listdir(Skirt) + os.listdir(Tee)\n",
    "label = np.concatenate((Jumpsuit_label, Dress_label, Skirt_label, Tee_label))\n",
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I use CNN to classify the images in PyTorch\n",
    "class myClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myClassifier, self).__init__()\n",
    "        self.block1 = self.conv_block(c_in=3, c_out=128, dropout=0.1, kernel_size=5, stride=1, padding=2)\n",
    "        self.block2 = self.conv_block(c_in=128, c_out=64, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.block3 = self.conv_block(c_in=64, c_out=32, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.lastcnn = nn.Conv2d(in_channels=32, out_channels=4, kernel_size=75, stride=1, padding=0)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.lastcnn(x)\n",
    "        return x\n",
    "    def conv_block(self, c_in, c_out, dropout, **kwargs):\n",
    "        seq_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout)\n",
    "        )\n",
    "        return seq_block\n",
    "net = myClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering I don't have GPU and running time is too long, I only randomly use 200 images as training dataset\n",
    "def train(net):\n",
    "    for epoch in range(1):\n",
    "        for index in np.random.randint(0, len(label), 200):\n",
    "            optimizer.zero_grad()\n",
    "            image_path = 'SimplifiedFashionDataset/'+ label_name[label[index]] + '/' + file_name[index]\n",
    "            img = Image.open(image_path)\n",
    "            new = img.resize((300, 300))\n",
    "            data = asarray(new)\n",
    "            outputs = net(torch.from_numpy(-1+(2/255)*data).float().view(1, 3, 300, 300))\n",
    "            loss = criterion(outputs, torch.tensor([[[label[index]]]], dtype=torch.long))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(68)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I use 100 images as test dataset and 68 of them are predicted correctly\n",
    "#If I train them with more dataset, more time and use GPU to train, I believe the accuracy must be much higher\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for index in np.random.randint(0, len(label), 100):\n",
    "        image_path = 'SimplifiedFashionDataset/'+ label_name[label[index]] + '/' + file_name[index]\n",
    "        img = Image.open(image_path)\n",
    "        new = img.resize((300, 300))\n",
    "        data = asarray(new)\n",
    "        outputs = net(torch.from_numpy(-1+(2/255)*data).float().view(1, 3, 300, 300))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == label[index]).sum()\n",
    "correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
